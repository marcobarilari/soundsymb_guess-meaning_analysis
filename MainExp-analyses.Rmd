---
title: "Semantic Processing in SC and EB"
author: "Minah Chang"
date: "28 Feb 2022"
output: html_document
---

### Data preparation

From the data, "distractor trials" are discarded and not considered for further analyses.

* All Distractor trials were removed (4186 values)

```{r setup, include=FALSE}
# Load and install (if missing) the recquired packages
list.of.packages <- c("tidyverse", 
                      "knitr", 
                      "reshape2", 
                      "lme4",
                      "nlme",
                      "car")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

lapply(list.of.packages, library, character.only = TRUE)

# set script folder as working dir
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# set to true to show the code chunk
knitr::opts_chunk$set(echo = TRUE)
```

### Load processed and merged data

The header column is organized as follows:

* 1. pseudoid
* 2. group (EB or SC)
* 3. session (matlab or gorilla)
* 4. category (integer 1, 3, 4, 6-9)
    + category 1: size
    + category 3: brightness
    + category 4: loudness
    + category 6: velocity
    + category 7: movement
    + category 8: space
    + category 9: distance
* 5. wordcode
* 6. language
* 7. stimulus
* 8. meaning
* 9. value (good or goodop)
* 10. response
* 11. grade (1 if correct, 0 if incorrect)

*Native accuracy: given that some words in specific native languages groups can "sound" with the opposite meaning as presented in Tzeng (2017), we recompute the accuracy for those stimuli that in our prestudy were mapped systematically to the opposite meaning. For these subset of stimuli, we consider the response correct if it does not match the original meaning and incorrect if it does.

```{r}

allData<-read.csv("data/allData.csv", header = TRUE)

```

Check that all the participants have the same number of responses per category

```{r}

allData %>% 
  group_by(pseudoid, group, category) %>% 
  count() %>% 
  pivot_wider(names_from = category, values_from = n) %>% 
  print(n = 46)

```

### Analysis

*We chose mixed effect logistic regression over tradional statics (e.g., ANOVA) because they represent all source of variance and are better to modeling binomial categorical responses.

### Compute the raw accuracy

```{r}

allData$rawAccuracy <- as.integer(allData$response == allData$meaning)

allData %>%
  group_by(group) %>%
  summarize(rawAccuracy = mean(rawAccuracy), 
            .groups = 'keep')

allData$nativeAccuracy <- ifelse(allData$value == 'goodop', 
                                 abs(allData$rawAccuracy - 1), 
                                 allData$rawAccuracy + 0)

allData %>%
  group_by(group) %>%
  summarize(native_acc = mean(nativeAccuracy), 
            .groups = 'keep')

allData %>%
  group_by(group) %>%
  summarize(raw_acc = mean(rawAccuracy), 
            native_acc = mean(nativeAccuracy), 
            .groups = 'keep')

```

### Accuracy per group and category

Category 1: size
Category 3: brightness
Category 4: loudness
Category 6: velocity
Category 7: movement
Category 8: space
Category 9: distance

```{r}

categoryAccuracy_wide <- allData %>%
  group_by(category, group) %>%
  summarize(rawAccuracy = mean(rawAccuracy), nativeAccuracy = mean(nativeAccuracy), 
            .groups = 'keep') %>% 
  pivot_wider(names_from = group, values_from = c(rawAccuracy, nativeAccuracy))

print(categoryAccuracy_wide)

```

## Plot of the native accuracy per category.

```{r}

categoryAccuracy_tidy <- allData %>%
  group_by(group, category) %>%
  summarize(rawAccuracy_mean = mean(rawAccuracy), nativeAccuracy_mean = mean(nativeAccuracy), 
            rawAccuracy_sd = sd(rawAccuracy), nativeAccuracy_sd = sd(nativeAccuracy),
            n = n(),
            rawAccuracy_se = rawAccuracy_sd / sqrt(n), nativeAccuracy_se = nativeAccuracy_sd / sqrt(n),
            .groups = 'keep')

print(categoryAccuracy_tidy)

ggplot(data = categoryAccuracy_tidy, 
       aes(x = as.factor(category), y = nativeAccuracy_mean, fill = group)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_classic() +
  scale_fill_manual(values=c('grey52','darkorange1'), labels=c('Blind', 'Sighted')) +
  scale_y_continuous(limits=c(0, 0.85), breaks=seq(0, 0.85, 0.1), expand = c(0,0)) +
  scale_x_discrete(limits=c("1", "3", "4", "6", "7", "8", "9"),
                   labels = c("size", "brightness", "loudness", "velocity", "movement", "space", "distance")) + 
  geom_errorbar(aes(ymin = nativeAccuracy_mean - nativeAccuracy_se,
                    ymax = nativeAccuracy_mean + nativeAccuracy_se),
                width = .08,
                position = position_dodge(.9)) +
  labs(x="Category", y="Accuracy") +
  ggtitle("Native Accuracy") +
  theme(
    text=element_text(size=12), 
    axis.line = element_line(size = 0.6), 
    axis.text.x = element_text(size=10,colour="black",
                               angle = 13,
                               vjust = .5, 
                               hjust = 0.5), 
    axis.text.y = element_text(size=10, colour='black'), 
    legend.title=element_blank())+
  geom_hline(yintercept=c(0.5), linetype="dashed", colour="black", size=0.3)

```

### Are blind and sighted controls better than chance at detemining the meaning of the presented foreing words? Is there any difference between the two groups?

*We input main effect of semantic category and group and the interaction bewteen the two. We input as well random intercept by subject, item (each stimulus) and language (each language of the foreign words)

### Native Accuracy

```{r}

nativeResult <- glmer(nativeAccuracy ~ category + group + category*group +
        (1 | pseudoid) + (1 | language:stimulus), 
      data = allData,
      family = binomial,
      control = glmerControl(optimizer="bobyqa"))

summary(nativeResult)

Anova(nativeResult)

# calculate odd ratio and confidence intervals
se <- sqrt(diag(vcov(nativeResult)))
tab <- cbind(Est = fixef(nativeResult),
             LL = fixef(nativeResult) - 1.96 * se,
             UL = fixef(nativeResult) + 1.96 * se)

# print odd-ratio and confidence interval
print(exp(tab[2:4,]), digits=3)

```

## Post hoc analyses in case we see a difference between groups - Native accuracy

### Category 1: size

```{r}

cat1 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 1),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat1)

Anova(cat1)

catOne_EB <- subset(allData, category == 1 & group == 'EB')
binom.test(sum(catOne_EB$grade), nrow(catOne_EB), p = .5)

catOne_SC <- subset(allData, category == 1 & group == 'SC')
binom.test(sum(catOne_SC$grade), nrow(catOne_SC), p = .5)

```

### Category 3: brightness

```{r}

cat3 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 3),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat3)

Anova(cat3)

catThree_EB <- subset(allData, category == 3 & group == 'EB')
binom.test(sum(catThree_EB$grade), nrow(catThree_EB), p = .5)

catThree_SC <- subset(allData, category == 3 & group == 'SC')
binom.test(sum(catThree_SC$grade), nrow(catThree_SC), p = .5)

```

### Category 4: loudness

```{r}

cat4 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 4),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat4)

Anova(cat4)

catFour_EB <- subset(allData, category == 4 & group == 'EB')
binom.test(sum(catFour_EB$grade), nrow(catFour_EB), p = .5)

catFour_SC <- subset(allData, category == 4 & group == 'SC')
binom.test(sum(catFour_SC$grade), nrow(catFour_SC), p = .5)

```

### Category 6: velocity

```{r}

cat6 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 6),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat6)

Anova(cat6)

catSix_EB <- subset(allData, category == 6 & group == 'EB')
binom.test(sum(catSix_EB$grade), nrow(catSix_EB), p = .5)

catSix_SC <- subset(allData, category == 6 & group == 'SC')
binom.test(sum(catSix_SC$grade), nrow(catSix_SC), p = .5)

```

### Category 7: movement

```{r}

cat7 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 7),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat7)

Anova(cat7)

catSeven_EB <- subset(allData, category == 7 & group == 'EB')
binom.test(sum(catSeven_EB$grade), nrow(catSeven_EB), p = .5)

catSeven_SC <- subset(allData, category == 7 & group == 'SC')
binom.test(sum(catSeven_SC$grade), nrow(catSeven_SC), p = .5)

```

### Category 8: space

```{r}

cat8 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 8),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat8)

Anova(cat8)

catEight_EB <- subset(allData, category == 8 & group == 'EB')
binom.test(sum(catEight_EB$grade), nrow(catEight_EB), p = .5)

catEight_SC <- subset(allData, category == 8 & group == 'SC')
binom.test(sum(catEight_SC$grade), nrow(catEight_SC), p = .5)

```

### Category 9: distance

```{r}

cat9 = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, category == 9),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(cat9)

Anova(cat9)

catNine_EB <- subset(allData, category == 8 & group == 'EB')
binom.test(sum(catNine_EB$grade), nrow(catNine_EB), p = .5)

catNine_SC <- subset(allData, category == 8 & group == 'SC')
binom.test(sum(catNine_SC$grade), nrow(catNine_SC), p = .5)

```

### Native Accuracy Opposite Words

```{r}

big = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "big"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(big)

Anova(big)

big_EB <- subset(allData, meaning == "big" & group == 'EB')
binom.test(sum(big_EB$grade), nrow(big_EB), p = .5)

big_SC <- subset(allData, meaning == "big" & group == 'SC')
binom.test(sum(big_EB$grade), nrow(big_EB), p = .5)

```


```{r}

small = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "small"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(small)

Anova(small)

small_EB <- subset(allData, meaning == "small" & group == 'EB')
binom.test(sum(small_EB$grade), nrow(small_EB), p = .5)

small_SC <- subset(allData, meaning == "small" & group == 'SC')
binom.test(sum(small_EB$grade), nrow(small_EB), p = .5)

```


```{r}

bright = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "bright"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(bright)

Anova(bright)

bright_EB <- subset(allData, meaning == "bright" & group == 'EB')
binom.test(sum(bright_EB$grade), nrow(bright_EB), p = .5)

bright_SC <- subset(allData, meaning == "bright" & group == 'SC')
binom.test(sum(bright_SC$grade), nrow(bright_SC), p = .5)

```


```{r}

dark = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "dark"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(dark)

Anova(dark)

dark_EB <- subset(allData, meaning == "dark" & group == 'EB')
binom.test(sum(dark_EB$grade), nrow(dark_EB), p = .5)

dark_SC <- subset(allData, meaning == "dark" & group == 'SC')
binom.test(sum(dark_SC$grade), nrow(dark_SC), p = .5)

```


```{r}

loud = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "loud"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(loud)

Anova(loud)

loud_EB <- subset(allData, meaning == "loud" & group == 'EB')
binom.test(sum(loud_EB$grade), nrow(loud_EB), p = .5)

loud_SC <- subset(allData, meaning == "loud" & group == 'SC')
binom.test(sum(loud_SC$grade), nrow(loud_SC), p = .5)

```


```{r}

quiet = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "quiet"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(quiet)

Anova(quiet)

quiet_EB <- subset(allData, meaning == "quiet" & group == 'EB')
binom.test(sum(quiet_EB$grade), nrow(quiet_EB), p = .5)

quiet_SC <- subset(allData, meaning == "quiet" & group == 'SC')
binom.test(sum(quiet_SC$grade), nrow(quiet_SC), p = .5)

```


```{r}

fast = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "fast"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(fast)

Anova(fast)

fast_EB <- subset(allData, meaning == "fast" & group == 'EB')
binom.test(sum(fast_EB$grade), nrow(fast_EB), p = .5)

fast_SC <- subset(allData, meaning == "fast" & group == 'SC')
binom.test(sum(fast_SC$grade), nrow(fast_SC), p = .5)

```


```{r}

slow = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "slow"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(slow)

Anova(slow)

slow_EB <- subset(allData, meaning == "slow" & group == 'EB')
binom.test(sum(slow_EB$grade), nrow(slow_EB), p = .5)

slow_SC <- subset(allData, meaning == "slow" & group == 'SC')
binom.test(sum(slow_SC$grade), nrow(slow_SC), p = .5)

```


```{r}

moving = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "moving"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(moving)

Anova(moving)

moving_EB <- subset(allData, meaning == "moving" & group == 'EB')
binom.test(sum(moving_EB$grade), nrow(moving_EB), p = .5)

moving_SC <- subset(allData, meaning == "moving" & group == 'SC')
binom.test(sum(moving_SC$grade), nrow(moving_SC), p = .5)

```


```{r}

still = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "still"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(still)

Anova(still)

still_EB <- subset(allData, meaning == "still" & group == 'EB')
binom.test(sum(still_EB$grade), nrow(still_EB), p = .5)

still_SC <- subset(allData, meaning == "still" & group == 'SC')
binom.test(sum(still_SC$grade), nrow(still_SC), p = .5)

```


```{r}

down = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "down"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(down)

Anova(down)

down_EB <- subset(allData, meaning == "down" & group == 'EB')
binom.test(sum(down_EB$grade), nrow(down_EB), p = .5)

down_SC <- subset(allData, meaning == "down" & group == 'SC')
binom.test(sum(down_SC$grade), nrow(down_SC), p = .5)

```


```{r}

up = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "up"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(up)

Anova(up)

up_EB <- subset(allData, meaning == "up" & group == 'EB')
binom.test(sum(up_EB$grade), nrow(up_EB), p = .5)

up_SC <- subset(allData, meaning == "up" & group == 'SC')
binom.test(sum(up_SC$grade), nrow(up_SC), p = .5)

```


```{r}

far = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "far"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(far)

Anova(far)

far_EB <- subset(allData, meaning == "far" & group == 'EB')
binom.test(sum(far_EB$grade), nrow(far_EB), p = .5)

far_SC <- subset(allData, meaning == "far" & group == 'SC')
binom.test(sum(far_SC$grade), nrow(far_SC), p = .5)

```


```{r}

near = glmer(nativeAccuracy ~ group +
        (1 | pseudoid) + (1 | language:stimulus),
      subset(allData, meaning == "near"),
      family = binomial,
      control=glmerControl(optimizer="bobyqa"))

summary(near)

Anova(near)

near_EB <- subset(allData, meaning == "near" & group == 'EB')
binom.test(sum(near_EB$grade), nrow(near_EB), p = .5)

near_SC <- subset(allData, meaning == "near" & group == 'SC')
binom.test(sum(near_SC$grade), nrow(near_SC), p = .5)

```


```{r}

adjAccuracy_tidy <- allData %>%
  group_by(group, meaning) %>%
  summarize(rawAccuracy = mean(rawAccuracy), nativeAccuracy = mean(nativeAccuracy), 
            .groups = 'keep')

ggplot(data = adjAccuracy_tidy, 
       aes(x = as.factor(meaning), y = nativeAccuracy, fill = group)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_classic() +
  scale_fill_manual(values=c('grey52','darkorange1'), labels=c('Blind', 'Sighted')) +
  scale_y_continuous(limits=c(0, 0.85), breaks=seq(0, 0.85, 0.1), expand = c(0,0)) +
  scale_x_discrete(limits=c("big", "small", "bright", "dark", "loud", "quiet", "fast", "slow", "moving", "still", "down", "up", "far", "near"),
                   labels = c("big", "small", "bright", "dark", "loud", "quiet", "fast", "slow", "moving", "still", "down", "up", "far", "near")) + 
  labs(x="Adjectives", y="Accuracy") +
  ggtitle("Native Accuracy") +
  theme(
    text=element_text(size=12), 
    axis.line = element_line(size = 0.6), 
    axis.text.x = element_text(size=10,colour="black",
                               angle = 13,
                               vjust = .5, 
                               hjust = 0.5), 
    axis.text.y = element_text(size=10, colour='black'), 
    legend.title=element_blank())+
  geom_hline(yintercept=c(0.5), linetype="dashed", colour="black", size=0.3)


```




